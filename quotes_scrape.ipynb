{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import random\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.firefox.options import Options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scroll(driver, timeout):\n",
    "    scroll_pause_time = timeout\n",
    "\n",
    "    # Get scroll height\n",
    "    last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "\n",
    "    while True:\n",
    "        # Scroll down to bottom\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "\n",
    "        # Wait to load page\n",
    "        time.sleep(scroll_pause_time)\n",
    "\n",
    "        # Calculate new scroll height and compare with last scroll height\n",
    "        new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "        if new_height == last_height:\n",
    "            # If heights are the same it will exit the function\n",
    "            break\n",
    "        last_height = new_height\n",
    "\n",
    "options = Options()\n",
    "options.set_preference('permissions.default.image', 2)\n",
    "options.set_preference('dom.ipc.plugins.enabled.libflashplayer.so', False)\n",
    "\n",
    "\n",
    "def get_quotes(url):\n",
    "    # Setup the driver. This one uses firefox with some options and a path to the geckodriver\n",
    "    driver = webdriver.Firefox(options=options, executable_path='/usr/local/bin/geckodriver')\n",
    "    # implicitly_wait tells the driver to wait before throwing an exception\n",
    "    driver.implicitly_wait(10)\n",
    "    # driver.get(url) opens the page\n",
    "    driver.get(url)\n",
    "    # This starts the scrolling by passing the driver and a timeout\n",
    "    scroll(driver, 3)\n",
    "    # Once scroll returns bs4 parsers the page_source\n",
    "    soup = BeautifulSoup(driver.page_source, 'lxml')\n",
    "    # Them we close the driver as soup_a is storing the page source\n",
    "    driver.close()\n",
    "\n",
    "    quotes = []\n",
    "    authors = []\n",
    "    for quote in soup.find_all('a', {'title': 'view quote'}):\n",
    "        quotes.append(\"'\" + quote.contents[0] + \"'\")\n",
    "    for author in soup.find_all('a', {'title': 'view author'}):\n",
    "        authors.append(\" \" + author.contents[0])\n",
    "    quotes = pd.Series(quotes, name='quote')\n",
    "    authors = pd.Series(authors, name='author')\n",
    "    quotes_authors = pd.concat([quotes, authors], axis=1)\n",
    "    return quotes_authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.brainyquote.com/topics'\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.text, 'lxml')\n",
    "links = []\n",
    "for a in soup.find_all('a'):\n",
    "    links.append(a.get('href'))\n",
    "links = links[links.index('/topics/age-quotes'):(links.index('/topics/work-quotes') + 1)]\n",
    "full_links = ['http://www.brainyquote.com' + link + '.html' for link in links]\n",
    "topics = [link[8:(link.index('q')-1)] for link in links]\n",
    "topics_links = dict(zip(topics, full_links))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "subtopics = ['age', 'alone', 'anger', 'art', 'attitude', 'beauty', 'change', 'courage', 'death', 'dreams', 'experience',\n",
    "            'failure', 'faith', 'fear', 'forgiveness', 'friendship', 'funny', 'god', 'happiness', 'humor', 'inspirational',\n",
    "            'knowledge', 'learning' ,'life', 'love', 'marriage' ,'motivational', 'music', 'nature' ,'patience',\n",
    "            'sad', 'success' ,'teacher' ,'thankful', 'time', 'wisdom']\n",
    "url_fetch = [topics_links[u] for u in subtopics]\n",
    "full = pd.DataFrame()\n",
    "for u in url_fetch:\n",
    "    new = get_quotes(u)\n",
    "    new['label'] = str(list(topics_links.keys())[list(topics_links.values()).index(u)])\n",
    "    full = pd.concat([full, new], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num of duplicates: 1930\n"
     ]
    }
   ],
   "source": [
    "print('num of duplicates:', full.duplicated(subset=['quote'], keep='first').sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_drop = full.drop(full.loc[full.duplicated(subset=['quote'], keep='first') == True].index, axis=0)\n",
    "full_drop.to_csv('full_quotes.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
